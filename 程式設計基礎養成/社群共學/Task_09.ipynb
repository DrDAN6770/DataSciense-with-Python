{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "vZ4-BU5SXhiZ",
        "o1a1E2-cYMBS",
        "g5TYAK6jZVau"
      ],
      "authorship_tag": "ABX9TyNQtEQUwxLeDYysGBfumtsw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DrDAN6770/DataSciense-with-Python/blob/Python-%E7%A8%8B%E5%BC%8F%E8%A8%AD%E8%A8%88%E5%9F%BA%E7%A4%8E%E9%A4%8A%E6%88%90_%E5%AF%A6%E6%88%B0-%E7%A4%BE%E7%BE%A4%E5%85%B1%E5%AD%B8/Task_09.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 作業#01 【實作題】新聞語料關鍵字分析"
      ],
      "metadata": {
        "id": "WoyePX5jXa0c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1 斷詞（tokenize）\n",
        "\n",
        "---\n",
        "所謂的斷詞（tokenize）是指將文本中的「單字」萃取而出的動作，請問中文字和英文字在斷詞處理上可能有哪些差異存在呢？\n"
      ],
      "metadata": {
        "id": "iw1m8li2gmDE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "英文就是單字和單字之間\n",
        "\n",
        "中文大概是詞性吧，所以不太容易處理"
      ],
      "metadata": {
        "id": "0HYFXY0yguCR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2 爬蟲\n",
        "\n",
        "---\n",
        "\n",
        "第一個步驟請利用 聯合新聞網 作為主要的文本來源，將範例收集回來的新聞內文存在一個 List 容器變數 `news` 內"
      ],
      "metadata": {
        "id": "ofF6ViNTg_Lj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "id": "0W3C2NSehLyG"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 利用 requests 對 API 來源發送一個請求\n",
        "url = 'https://udn.com/news/breaknews/1'\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.text)\n",
        "\n",
        "news = []\n",
        "\n",
        "for link in soup.find_all('h3', class_='rounded-thumb__title')[:4]:\n",
        "  news_url = link.a['href']\n",
        "  news_response = requests.get('https://udn.com' + news_url)\n",
        "  news_soup = BeautifulSoup(news_response.text)\n",
        "  news_content = news_soup.find('div', class_='article-content__paragraph').text.strip().replace('\\n', ' ')\n",
        "  \n",
        "  news.append(news_content)\n",
        "print(news)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZPjzgvbhJ8V",
        "outputId": "c66e957b-18d7-40f9-87bc-873f2091cd83"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['最近天氣越來越熱，許多人已將厚重衣物收起，換上輕薄舒適的穿搭。然而，就有一名男大生PO文表示，近日逛夜市時發現，不少女生都會穿著很透很薄的白長褲，有時還無法完全遮住內褲顏色，因此好奇發問「我還是不太懂為什麼會想這樣穿？」掀起網友熱議。 \\r 該名男大生在《Dcard》發文表示，前幾天逛夜市發現，一堆女生都會穿著很透很薄的白長褲，「輕則露出內褲痕，嚴重一點我連她穿什麼樣式顏色的內褲都看得出來」，讓他不禁疑惑問道「女生都喜歡穿透明白長褲？我還是不太懂為什麼會想這樣穿？」            \\r 貼文一出，引發網友熱烈討論，紛紛留言「確實三不五時會看到這種的，我也真的很納悶為什麼要這樣」、「我是女生，我也不懂」、「之前也有看過，還在我面前彎腰，內褲看得一清二楚」、「因為通常大家穿完褲子是在家，光沒那麼強烈，所以照鏡子時不一定會發現褲子很透」、「我覺得有時候室內外看起來會不太一樣，覺得很多人不是刻意的，是買到品質不好太薄的」。 \\r 此外，還有網友提到「她不知道，結案。之前我們教授也這樣穿，我還去提醒她，她根本不知道內褲花色看得一清二楚」、「我覺得是因為自己看不到後面，所以才不小心穿出門的…我上次也提醒我同學，而且我也超怕自己這樣，超尷尬」、「所以我買白長褲都會特別注意，很多內褲痕真的好明顯，但想要那種垂墜的型，布料通常又薄又貼膚，所以一定很明顯」、「我就是那種女生，覺得褲子好看就不在意」。    女生 Dcard', '新北市有民眾發現一名男子在前天白天跪在林口交流道，舉著牌子「媽媽住院請幫忙」，引人矚目，警察到場後，男子卻轉頭就跑，連牌子也不要了，林口區公所社會課發現，這名男子住在桃園，家中母親並沒有狀況，男子已3年沒跟家裡連繫，也不願多談細節並拒絕協助。 \\r 一名網友在臉書社團「林口大家庭LinKou-Family」PO出照片，發現一名男子跪在林口南下交流道的道路旁，還舉著保麗龍板「媽媽住院請幫忙」，看似尋求援助，引來周邊民眾關注。            \\r 不過，林口分局、新北市議員蔡淑君獲報後，都前往現場關心。不過這名男子一看到警察就丟掉牌子，轉頭想跑，警方趕緊上前關心，希望了解詳情。 \\r 林口區長廖武輝指出，林口分局員警、林口區公所詢問男子狀況時，他只願意提供身分證字號及姓名，警方希望能幫忙，但男子都拒絕提供其他相關資料，也拒絕幫忙。後來發現男子是桃園中壢人，就將他轉介至桃園市社福機構。 \\r 廖武輝說，桃園方經了解後發現，這名男子家庭狀況並沒有問題，母親安在，男子也不是低收入戶，警方直接與他接觸時，也沒有精神異常的感覺，目前只能積極聯繫當事人，了解他是否需要協助。 \\r 新北市議員蔡淑君則說，該男子當天在國道1號林口區南下匝道口舉牌下跪，但警方到現場後，他又將牌子丟掉，拒絕協助。後續警方詢問，確認是桃園市的民眾，自稱從事殯葬業，但經濟狀況不穩定，加上媽媽長期住院因此才出來舉牌。不過據了解，該男子疑似有前科，且鄰居說他已經很久沒跟家裡聯絡，媽媽也沒有住院。一名男子在林口交流道舉牌「媽媽住院請幫忙」，然而警察想上前協助，男子卻轉頭就跑，經查，該男子家中並無狀況。圖／擷自臉書社團「林口大家庭LinKou-Family」    林口 桃園', '在國外容易遇到語言不通的問題，最好的方法是先確認過後再行動。有一名網友透露，最近和朋友在東京吃烏龍麵時，看到日文「玉」直覺是雞蛋，結果和友人各點了三顆，心想不用加價好划算，結果送來時悲劇了。 \\r 網友在臉書社團「爆廢公社」發文表示，最近和朋友到東京玩，晚餐吃烏龍麵，結果看到菜單上寫著「3つ玉」，腦袋一閃「玉就是雞蛋嘛這題我會」，心想著加雞蛋竟然免錢，於是和朋友都點了「3つ玉」。            \\r 沒想到烏龍麵送來的時候他們傻眼，因為日文的「3つ玉」其實是三坨麵的意思，結果份量多到和朋友都吃不完，「我還想說為什麼我們吃的這麼辛苦」，原po也自嘲「抱歉我今天是失格旅人，我不該被生出來」，他也驚訝隔壁的日本人食量驚人，都吃光光。 \\r 網友也紛紛留言回應，「玉子才是雞蛋」、「學一半，糗了！」、「這事我也做過，好在是加了一坨麵」、「沒事，我四年前在九州outlet也做過，兩碗大盛加三玉以為是加蛋這種事，店員一再跟我確認，我只會OKOK 3q3q，結果麵來了我自己都嚇到」、「不好意思我笑了，而且免費的沒吃完是很失禮的事啊」。     東京', '宜蘭29歲女孩林恩羽充滿愛心、熱心助人，希望成為義消幫助更多人，她努力朝夢想前進，去年底考取救護證照，眼見即將如願，日前卻因意外不幸離世。議長張勝德得知女孩的動人故事，決定幫她圓夢，今天由縣消防局頒發義消服務證及制服由林母代收，祝福這位美麗天使繼續在天上助人。 \\r 林恩羽的母親表示，女兒從小就充滿正義感、很有愛心，看到受傷的貓狗會帶回來照顧，路上目睹車禍受傷的人也想去幫忙，但因本身並沒有救護人員證照，擔心會有糾紛，於是女兒透過努力提升救護技能，期盼能成為一位義消，可以幫助更多人。            美麗的林恩羽獲頒義消服務證，圓了她生前的夢想。記者戴永華／攝影\\r 女孩原本是美髮設計師，3年前因為疫情，轉而從事臨終造型設計師，母親曾經問她「不害怕嗎？」她說，覺得自己在做善事，第一次服務的對象是沒人善後處理的腐屍，林恩羽幫忙恢復容貌，讓對方有尊嚴離開。 \\r 不料3年前，跟她感情非常好的父親走了，林恩羽哀痛逾恆，走不出情緒；有一次她抱著父親的骨灰罈放在駕駛座旁，淚眼開車「載著爸爸去兜風」；也大概在此時，她在臉書認識不少義消好朋友，去年底努力通過魔鬼訓練，如願取得初級救護技術人員證照，正當開心可以成為義消投入服務時，卻因意外不幸離世。 \\r 母親與姐姐百般不捨，義消朋友潘宗佑說，前一陣子有夢到恩羽，笑著揮手，好像要跟他講什麼事。議長張勝德接到訃文時，得知這位女孩的感人故事，決定幫她圓夢，協助向縣消防局爭取，今天頒發義消服務證及一套全新制服，轉交母親將帶去恩羽靈前，幫她圓了最後一個夢。 \\r 張勝德表示，義消服務證的有效期限空白，沒有寫日期，即便這位暖心的女孩走了，「我們希望她永遠都是義消志工」，在天上快樂當天使，繼續去幫助她想要幫助的人。林恩羽榮獲追贈義消服務證及一套全新制服，她生前的義消好友今天也來見證感人的一刻。記者戴永華／攝影宜蘭縣消防局、議長張勝德追贈義消服務證及制服給美麗天使林恩羽，期盼她在天上繼續熱心助人。記者戴永華／攝影宜蘭縣消防局、議長張勝德追贈義消服務證及制服給美麗天使林恩羽，期盼她在天上繼續熱心助人。記者戴永華／攝影林恩羽的義消服務證的背面沒有填寫有效期限，她將是宜蘭永遠的義消志工。記者戴永華／攝影    制服']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3 下載官方字典檔及安裝jieba\n",
        "\n",
        "---\n",
        "在 Colab 中使用 pip 安裝 `jieba` 斷詞套件與相關工具。Hint：指令前加上 ! 符號即可在 Colab 中執行 pip 指令\n"
      ],
      "metadata": {
        "id": "1V9fr4YYnZGX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 安裝 jieba 中文斷詞套件\n",
        "!pip install jieba \n",
        "\n",
        "# 下載官方字典檔\n",
        "!wget https://raw.githubusercontent.com/fxsjy/jieba/master/extra_dict/dict.txt.big\n",
        "\n",
        "# 載入套件與字典檔\n",
        "import jieba\n",
        "jieba.load_userdict(\"dict.txt.big\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_2sYW10nh21",
        "outputId": "1d2532af-2ba6-4e00-c599-ec3a362580ba"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.9/dist-packages (0.42.1)\n",
            "--2023-04-03 10:16:39--  https://raw.githubusercontent.com/fxsjy/jieba/master/extra_dict/dict.txt.big\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8583143 (8.2M) [text/plain]\n",
            "Saving to: ‘dict.txt.big’\n",
            "\n",
            "dict.txt.big        100%[===================>]   8.18M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2023-04-03 10:16:40 (95.7 MB/s) - ‘dict.txt.big’ saved [8583143/8583143]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4 抓斷詞\n",
        "\n",
        "---\n",
        "\n",
        "接下來請將每篇新聞文章斷詞後的結果存入 `tokens` 變數，並且將斷詞後的結果計算成每個單字的出現次數（詞頻），並存成以「出現單字為 KEY、出現次數為 Value」的 dict 型態變數 `word_count`"
      ],
      "metadata": {
        "id": "fb3ALx7Lpbes"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 精確模式斷詞\n",
        "tokens = []\n",
        "for d in news:\n",
        "  token = list(jieba.cut(d,HMM=False)) # token = d 字串斷詞結果\n",
        "  tokens.extend(token)\n",
        "\n",
        "# 將斷詞後的結果計算成每個單字的出現次數（詞頻）\n",
        "word_count = {}\n",
        "exclude_set = ['「', '」', '，', '『', '』', '。', '“', ' ', '、', '.', '-', '!', '？', '！', '：', ':', '／', '（', '）']\n",
        "for k in tokens:\n",
        "  if k in exclude_set:\n",
        "    continue # 跳過那些標點符號\n",
        "  word_count[k] = word_count.setdefault(k,0) + 1\n",
        "\n",
        "print(word_count)\n",
        "# {'聲明': 4, '主管機關': 3, ...}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqUzuYWYps0X",
        "outputId": "3e16fe15-3ab3-44b9-80aa-6ba93fd7e1d8"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'最近': 3, '天氣': 1, '越來越': 1, '熱': 2, '許多': 1, '人': 8, '已將': 1, '厚重': 1, '衣物': 1, '收起': 1, '換上': 1, '輕薄': 1, '舒適': 1, '的': 40, '穿': 7, '搭': 1, '然而': 2, '就': 7, '有': 10, '一名': 6, '男': 2, '大生': 2, 'PO': 2, '文': 2, '表示': 5, '近日': 1, '逛': 2, '夜市': 2, '時': 7, '發現': 8, '不少': 2, '女生': 6, '都': 11, '會': 10, '穿著': 2, '很': 7, '透': 3, '很薄': 2, '白': 3, '長褲': 4, '有時': 1, '還': 5, '無法': 1, '完全': 1, '遮住': 1, '內褲': 6, '顏色': 2, '因此': 2, '好奇': 1, '發問': 1, '我': 24, '還是': 2, '不': 14, '太': 3, '懂': 3, '為': 12, '什麼': 6, '想': 6, '這樣': 5, '掀起': 1, '網友': 7, '議': 1, '\\r': 16, '該': 4, '名': 4, '在': 22, '《': 1, 'Dcard': 2, '》': 1, '發文': 2, '前': 2, '幾天': 1, '一堆': 1, '輕': 1, '則': 2, '露出': 1, '痕': 2, '嚴重': 1, '一點': 1, '連': 2, '她': 20, '樣式': 1, '看得出來': 1, '讓': 2, '他': 9, '不禁': 1, '疑惑': 1, '問道': 1, '喜歡': 1, '穿透': 1, '明白': 1, '貼': 1, '一出': 1, '引發': 1, '熱烈': 1, '討論': 1, '紛紛': 2, '留言': 2, '確實': 1, '三': 3, '五': 1, '時會': 1, '看到': 5, '這種': 2, '也': 20, '真的': 2, '納悶': 1, '要': 2, '是': 17, '之前': 2, '看過': 1, '面前': 1, '彎腰': 1, '看': 2, '得': 2, '一清二楚': 2, '因': 7, '通常': 2, '大家': 1, '完': 2, '褲子': 3, '在家': 1, '光': 1, '沒': 4, '那麼': 1, '強烈': 1, '所以': 4, '照鏡子': 1, '一定': 2, '覺得': 5, '有時候': 1, '室內外': 1, '看起來': 1, '一樣': 1, '很多': 2, '不是': 2, '刻意': 1, '買': 2, '到': 6, '品質': 1, '不好': 1, '太薄': 1, '此外': 1, '還有': 1, '提到': 1, '知道': 2, '結案': 1, '我們': 3, '教授': 1, '去': 5, '提醒': 2, '根本': 1, '花色': 1, '自己': 4, '看不到': 1, '後面': 1, '才': 3, '小心': 1, '出門': 1, '…': 1, '上次': 1, '同學': 1, '而且': 2, '超': 2, '怕': 1, '尷尬': 1, '特別注意': 1, '好': 5, '明顯': 2, '但': 5, '想要': 2, '那種': 2, '垂': 1, '墜': 1, '型': 1, '布料': 1, '又': 3, '薄': 1, '貼膚': 1, '就是': 2, '好看': 1, '不在意': 1, '新': 3, '北': 3, '市': 1, '民': 3, '眾': 3, '男子': 16, '前天': 1, '白天': 1, '跪': 2, '林口': 12, '交流': 3, '道': 4, '舉': 5, '著': 7, '牌子': 4, '媽媽': 5, '住院': 5, '請': 3, '幫忙': 7, '引人矚目': 1, '警察': 3, '到場': 1, '後': 4, '卻': 4, '轉頭': 3, '跑': 3, '不要': 1, '了': 12, '區公所': 2, '社會': 1, '課': 1, '這': 4, '住': 1, '桃園': 4, '家中': 2, '母親': 6, '並': 5, '沒有': 7, '狀況': 5, '已': 1, '3': 6, '年': 1, '跟': 5, '家': 2, '裡': 2, '連繫': 1, '願': 1, '多': 4, '談': 1, '細節': 1, '拒絕': 4, '協助': 5, '臉': 4, '書社': 3, '團': 3, '大家庭': 2, 'LinKou': 2, 'Family': 2, '出': 2, '照片': 1, '南下': 2, '路旁': 1, '保麗龍': 1, '板': 1, '看似': 1, '尋求': 1, '援助': 1, '引來': 1, '周邊': 1, '關注': 1, '不過': 3, '分局': 2, '市議員': 2, '蔡': 2, '淑': 2, '君': 2, '獲': 1, '報': 1, '前往': 1, '現場': 2, '關心': 2, '一': 3, '丟掉': 2, '警方': 5, '趕緊': 1, '上前': 2, '希望': 4, '了解': 4, '詳情': 1, '區長': 1, '廖': 2, '武': 2, '輝': 2, '指出': 1, '員警': 1, '詢問': 2, '只': 2, '願意': 1, '提供': 2, '身分證': 1, '字號': 1, '及': 6, '姓名': 1, '能': 2, '其他': 1, '相關': 1, '資料': 1, '後來': 1, '中壢人': 1, '將': 4, '轉': 1, '介': 1, '至': 1, '桃園市': 2, '社': 1, '福': 1, '機構': 1, '說': 6, '方': 1, '經': 1, '家庭': 1, '問題': 2, '安': 1, '低收入': 1, '戶': 1, '直接': 1, '與': 2, '接觸': 1, '精神異常': 1, '感覺': 1, '目前': 1, '只能': 1, '積極': 1, '聯繫': 1, '當事人': 1, '是否': 1, '需要': 1, '當天': 2, '國道': 1, '1': 1, '號': 1, '區': 1, '匝道': 1, '口': 1, '牌': 3, '下跪': 1, '後續': 1, '確認': 3, '自稱': 1, '從事': 2, '殯葬': 1, '業': 1, '經濟': 1, '穩定': 1, '加上': 1, '長期': 1, '出來': 2, '據': 1, '疑似': 1, '前科': 1, '且': 1, '鄰居': 1, '已經': 1, '很久沒': 1, '聯絡': 1, '經查': 1, '無': 1, '圖': 1, '擷': 1, '自': 1, '國外': 1, '容易': 1, '遇到': 1, '語言不通': 1, '最好': 1, '方法': 1, '先': 1, '過後': 1, '再': 1, '行動': 1, '透露': 1, '和': 5, '朋友': 6, '東京': 3, '吃': 5, '烏龍': 3, '麵': 6, '日文': 2, '玉': 7, '直覺': 1, '雞蛋': 4, '結果': 5, '友人': 1, '各': 1, '點': 2, '三顆': 1, '心想': 2, '不用': 1, '加價': 1, '划算': 1, '送': 1, '來時': 1, '悲劇': 1, '爆': 1, '廢': 1, '公社': 1, '玩': 1, '晚餐': 1, '菜單': 1, '上': 1, '寫': 2, 'つ': 3, '腦袋': 1, '閃': 1, '嘛': 1, '題': 1, '我會': 1, '加': 4, '竟然': 1, '免': 1, '錢': 1, '於是': 2, '沒想到': 1, '送來': 1, '時候': 1, '他們': 1, '傻眼': 1, '其實': 1, '坨': 2, '意思': 1, '份量': 1, '吃不完': 1, '這麼': 1, '辛苦': 1, '原': 1, 'po': 1, '自嘲': 1, '抱歉': 1, '今天': 4, '失': 1, '格': 1, '旅人': 1, '不該': 1, '被': 1, '生': 1, '驚訝': 1, '隔壁': 1, '日本': 1, '食量': 1, '驚人': 1, '光光': 1, '回': 1, '應': 1, '子': 1, '學': 1, '一半': 1, '糗': 1, '這事': 1, '做': 3, '過': 2, '沒事': 1, '四年': 1, '九州': 1, 'outlet': 1, '兩碗': 1, '大': 1, '盛': 1, '以': 1, '蛋': 1, '事': 3, '店員': 1, '一再': 1, 'OKOK': 1, '3q3q': 1, '來': 2, '嚇': 1, '不好意思': 1, '笑': 2, '免費': 1, '失禮': 1, '啊': 1, '宜蘭': 2, '29': 1, '歲': 1, '女孩': 5, '林': 10, '恩': 11, '羽': 11, '充滿': 2, '愛心': 2, '熱心': 3, '助人': 4, '成': 3, '義': 16, '消': 16, '幫助': 4, '更': 2, '努力': 3, '朝': 1, '夢想': 2, '前進': 1, '去年底': 2, '考取': 1, '救護': 4, '證照': 3, '眼見': 1, '即將': 1, '如願': 2, '日前': 1, '意外': 2, '不幸': 2, '離世': 2, '議長': 4, '張': 5, '勝': 5, '德': 5, '得知': 2, '動人': 1, '故事': 2, '決定': 2, '幫': 3, '圓夢': 2, '由': 2, '縣': 2, '消防局': 4, '頒發': 2, '服務': 10, '證': 8, '制服': 6, '母': 1, '代收': 1, '祝福': 1, '這位': 3, '美麗': 4, '天使': 3, '繼續': 4, '天上': 4, '女兒': 2, '從小': 1, '正義感': 1, '受傷': 2, '貓': 1, '狗': 1, '帶': 2, '回來': 1, '照顧': 1, '路上': 1, '目睹': 1, '車禍': 1, '本身': 1, '人員': 1, '擔心': 1, '糾紛': 1, '透過': 1, '提升': 1, '技能': 1, '期盼': 3, '一位': 1, '可以': 2, '獲頒': 1, '圓': 2, '生前': 2, '記者': 5, '戴': 5, '永華': 5, '攝影': 5, '原本': 1, '美髮': 1, '設計師': 2, '年前': 2, '疫情': 1, '轉而': 1, '臨終': 1, '造型': 1, '曾經': 1, '問': 1, '害怕': 1, '嗎': 1, '善事': 1, '第一次': 1, '對象': 1, '善後處理': 1, '腐屍': 1, '恢復': 1, '容貌': 1, '對方': 1, '尊嚴': 1, '離開': 1, '不料': 1, '感情': 1, '非常': 1, '父親': 2, '走': 3, '哀痛': 1, '逾恆': 1, '情緒': 1, '；': 2, '一次': 1, '抱': 1, '骨灰罈': 1, '放在': 1, '駕駛座': 1, '旁': 1, '淚眼': 1, '開車': 1, '載': 1, '爸爸': 1, '兜風': 1, '大概': 1, '此時': 1, '書': 1, '認識': 1, '通過': 1, '魔鬼': 1, '訓練': 1, '取得': 1, '初級': 1, '技術人員': 1, '正當': 1, '開心': 1, '投入': 1, '姐姐': 1, '百般': 1, '捨': 1, '潘': 1, '宗': 1, '佑': 1, '前一陣子': 1, '夢': 2, '揮手': 1, '好像': 1, '講': 1, '接到': 1, '訃文': 1, '感人': 2, '向': 1, '爭取': 1, '一套': 2, '全新': 2, '轉交': 1, '靈前': 1, '最後': 1, '一個': 1, '有效期限': 2, '空白': 1, '日期': 1, '即便': 1, '暖': 1, '心': 1, '永遠都是': 1, '志': 2, '工': 2, '快樂': 1, '使': 1, '榮獲': 1, '追贈': 3, '好友': 1, '見證': 1, '一刻': 1, '宜蘭縣': 2, '給': 2, '背面': 1, '填寫': 1, '永遠': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#請利用 Python 將每個單字的出現次數（詞頻）依照出現次數由多到少進行排序\n",
        "word_count = dict(sorted(word_count.items(),key = lambda value:value[1],reverse = True))\n",
        "print(word_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POgTXninrzuh",
        "outputId": "53beea6b-a08d-4326-d571-e6c854217aea"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'的': 40, '我': 24, '在': 22, '她': 20, '也': 20, '是': 17, '\\r': 16, '男子': 16, '義': 16, '消': 16, '不': 14, '為': 12, '林口': 12, '了': 12, '都': 11, '恩': 11, '羽': 11, '有': 10, '會': 10, '林': 10, '服務': 10, '他': 9, '人': 8, '發現': 8, '證': 8, '穿': 7, '就': 7, '時': 7, '很': 7, '網友': 7, '因': 7, '著': 7, '幫忙': 7, '沒有': 7, '玉': 7, '一名': 6, '女生': 6, '內褲': 6, '什麼': 6, '想': 6, '到': 6, '母親': 6, '3': 6, '及': 6, '說': 6, '朋友': 6, '麵': 6, '制服': 6, '表示': 5, '還': 5, '這樣': 5, '看到': 5, '覺得': 5, '去': 5, '好': 5, '但': 5, '舉': 5, '媽媽': 5, '住院': 5, '並': 5, '狀況': 5, '跟': 5, '協助': 5, '警方': 5, '和': 5, '吃': 5, '結果': 5, '女孩': 5, '張': 5, '勝': 5, '德': 5, '記者': 5, '戴': 5, '永華': 5, '攝影': 5, '長褲': 4, '該': 4, '名': 4, '沒': 4, '所以': 4, '自己': 4, '道': 4, '牌子': 4, '後': 4, '卻': 4, '這': 4, '桃園': 4, '多': 4, '拒絕': 4, '臉': 4, '希望': 4, '了解': 4, '將': 4, '雞蛋': 4, '加': 4, '今天': 4, '助人': 4, '幫助': 4, '救護': 4, '議長': 4, '消防局': 4, '美麗': 4, '繼續': 4, '天上': 4, '最近': 3, '透': 3, '白': 3, '太': 3, '懂': 3, '三': 3, '褲子': 3, '我們': 3, '才': 3, '又': 3, '新': 3, '北': 3, '民': 3, '眾': 3, '交流': 3, '請': 3, '警察': 3, '轉頭': 3, '跑': 3, '書社': 3, '團': 3, '不過': 3, '一': 3, '牌': 3, '確認': 3, '東京': 3, '烏龍': 3, 'つ': 3, '做': 3, '事': 3, '熱心': 3, '成': 3, '努力': 3, '證照': 3, '幫': 3, '這位': 3, '天使': 3, '期盼': 3, '走': 3, '追贈': 3, '熱': 2, '然而': 2, '男': 2, '大生': 2, 'PO': 2, '文': 2, '逛': 2, '夜市': 2, '不少': 2, '穿著': 2, '很薄': 2, '顏色': 2, '因此': 2, '還是': 2, 'Dcard': 2, '發文': 2, '前': 2, '則': 2, '痕': 2, '連': 2, '讓': 2, '紛紛': 2, '留言': 2, '這種': 2, '真的': 2, '要': 2, '之前': 2, '看': 2, '得': 2, '一清二楚': 2, '通常': 2, '完': 2, '一定': 2, '很多': 2, '不是': 2, '買': 2, '知道': 2, '提醒': 2, '而且': 2, '超': 2, '明顯': 2, '想要': 2, '那種': 2, '就是': 2, '跪': 2, '區公所': 2, '家中': 2, '家': 2, '裡': 2, '大家庭': 2, 'LinKou': 2, 'Family': 2, '出': 2, '南下': 2, '分局': 2, '市議員': 2, '蔡': 2, '淑': 2, '君': 2, '現場': 2, '關心': 2, '丟掉': 2, '上前': 2, '廖': 2, '武': 2, '輝': 2, '詢問': 2, '只': 2, '提供': 2, '能': 2, '桃園市': 2, '問題': 2, '與': 2, '當天': 2, '從事': 2, '出來': 2, '日文': 2, '點': 2, '心想': 2, '寫': 2, '於是': 2, '坨': 2, '過': 2, '來': 2, '笑': 2, '宜蘭': 2, '充滿': 2, '愛心': 2, '更': 2, '夢想': 2, '去年底': 2, '如願': 2, '意外': 2, '不幸': 2, '離世': 2, '得知': 2, '故事': 2, '決定': 2, '圓夢': 2, '由': 2, '縣': 2, '頒發': 2, '女兒': 2, '受傷': 2, '帶': 2, '可以': 2, '圓': 2, '生前': 2, '設計師': 2, '年前': 2, '父親': 2, '；': 2, '夢': 2, '感人': 2, '一套': 2, '全新': 2, '有效期限': 2, '志': 2, '工': 2, '宜蘭縣': 2, '給': 2, '天氣': 1, '越來越': 1, '許多': 1, '已將': 1, '厚重': 1, '衣物': 1, '收起': 1, '換上': 1, '輕薄': 1, '舒適': 1, '搭': 1, '近日': 1, '有時': 1, '無法': 1, '完全': 1, '遮住': 1, '好奇': 1, '發問': 1, '掀起': 1, '議': 1, '《': 1, '》': 1, '幾天': 1, '一堆': 1, '輕': 1, '露出': 1, '嚴重': 1, '一點': 1, '樣式': 1, '看得出來': 1, '不禁': 1, '疑惑': 1, '問道': 1, '喜歡': 1, '穿透': 1, '明白': 1, '貼': 1, '一出': 1, '引發': 1, '熱烈': 1, '討論': 1, '確實': 1, '五': 1, '時會': 1, '納悶': 1, '看過': 1, '面前': 1, '彎腰': 1, '大家': 1, '在家': 1, '光': 1, '那麼': 1, '強烈': 1, '照鏡子': 1, '有時候': 1, '室內外': 1, '看起來': 1, '一樣': 1, '刻意': 1, '品質': 1, '不好': 1, '太薄': 1, '此外': 1, '還有': 1, '提到': 1, '結案': 1, '教授': 1, '根本': 1, '花色': 1, '看不到': 1, '後面': 1, '小心': 1, '出門': 1, '…': 1, '上次': 1, '同學': 1, '怕': 1, '尷尬': 1, '特別注意': 1, '垂': 1, '墜': 1, '型': 1, '布料': 1, '薄': 1, '貼膚': 1, '好看': 1, '不在意': 1, '市': 1, '前天': 1, '白天': 1, '引人矚目': 1, '到場': 1, '不要': 1, '社會': 1, '課': 1, '住': 1, '已': 1, '年': 1, '連繫': 1, '願': 1, '談': 1, '細節': 1, '照片': 1, '路旁': 1, '保麗龍': 1, '板': 1, '看似': 1, '尋求': 1, '援助': 1, '引來': 1, '周邊': 1, '關注': 1, '獲': 1, '報': 1, '前往': 1, '趕緊': 1, '詳情': 1, '區長': 1, '指出': 1, '員警': 1, '願意': 1, '身分證': 1, '字號': 1, '姓名': 1, '其他': 1, '相關': 1, '資料': 1, '後來': 1, '中壢人': 1, '轉': 1, '介': 1, '至': 1, '社': 1, '福': 1, '機構': 1, '方': 1, '經': 1, '家庭': 1, '安': 1, '低收入': 1, '戶': 1, '直接': 1, '接觸': 1, '精神異常': 1, '感覺': 1, '目前': 1, '只能': 1, '積極': 1, '聯繫': 1, '當事人': 1, '是否': 1, '需要': 1, '國道': 1, '1': 1, '號': 1, '區': 1, '匝道': 1, '口': 1, '下跪': 1, '後續': 1, '自稱': 1, '殯葬': 1, '業': 1, '經濟': 1, '穩定': 1, '加上': 1, '長期': 1, '據': 1, '疑似': 1, '前科': 1, '且': 1, '鄰居': 1, '已經': 1, '很久沒': 1, '聯絡': 1, '經查': 1, '無': 1, '圖': 1, '擷': 1, '自': 1, '國外': 1, '容易': 1, '遇到': 1, '語言不通': 1, '最好': 1, '方法': 1, '先': 1, '過後': 1, '再': 1, '行動': 1, '透露': 1, '直覺': 1, '友人': 1, '各': 1, '三顆': 1, '不用': 1, '加價': 1, '划算': 1, '送': 1, '來時': 1, '悲劇': 1, '爆': 1, '廢': 1, '公社': 1, '玩': 1, '晚餐': 1, '菜單': 1, '上': 1, '腦袋': 1, '閃': 1, '嘛': 1, '題': 1, '我會': 1, '竟然': 1, '免': 1, '錢': 1, '沒想到': 1, '送來': 1, '時候': 1, '他們': 1, '傻眼': 1, '其實': 1, '意思': 1, '份量': 1, '吃不完': 1, '這麼': 1, '辛苦': 1, '原': 1, 'po': 1, '自嘲': 1, '抱歉': 1, '失': 1, '格': 1, '旅人': 1, '不該': 1, '被': 1, '生': 1, '驚訝': 1, '隔壁': 1, '日本': 1, '食量': 1, '驚人': 1, '光光': 1, '回': 1, '應': 1, '子': 1, '學': 1, '一半': 1, '糗': 1, '這事': 1, '沒事': 1, '四年': 1, '九州': 1, 'outlet': 1, '兩碗': 1, '大': 1, '盛': 1, '以': 1, '蛋': 1, '店員': 1, '一再': 1, 'OKOK': 1, '3q3q': 1, '嚇': 1, '不好意思': 1, '免費': 1, '失禮': 1, '啊': 1, '29': 1, '歲': 1, '朝': 1, '前進': 1, '考取': 1, '眼見': 1, '即將': 1, '日前': 1, '動人': 1, '母': 1, '代收': 1, '祝福': 1, '從小': 1, '正義感': 1, '貓': 1, '狗': 1, '回來': 1, '照顧': 1, '路上': 1, '目睹': 1, '車禍': 1, '本身': 1, '人員': 1, '擔心': 1, '糾紛': 1, '透過': 1, '提升': 1, '技能': 1, '一位': 1, '獲頒': 1, '原本': 1, '美髮': 1, '疫情': 1, '轉而': 1, '臨終': 1, '造型': 1, '曾經': 1, '問': 1, '害怕': 1, '嗎': 1, '善事': 1, '第一次': 1, '對象': 1, '善後處理': 1, '腐屍': 1, '恢復': 1, '容貌': 1, '對方': 1, '尊嚴': 1, '離開': 1, '不料': 1, '感情': 1, '非常': 1, '哀痛': 1, '逾恆': 1, '情緒': 1, '一次': 1, '抱': 1, '骨灰罈': 1, '放在': 1, '駕駛座': 1, '旁': 1, '淚眼': 1, '開車': 1, '載': 1, '爸爸': 1, '兜風': 1, '大概': 1, '此時': 1, '書': 1, '認識': 1, '通過': 1, '魔鬼': 1, '訓練': 1, '取得': 1, '初級': 1, '技術人員': 1, '正當': 1, '開心': 1, '投入': 1, '姐姐': 1, '百般': 1, '捨': 1, '潘': 1, '宗': 1, '佑': 1, '前一陣子': 1, '揮手': 1, '好像': 1, '講': 1, '接到': 1, '訃文': 1, '向': 1, '爭取': 1, '轉交': 1, '靈前': 1, '最後': 1, '一個': 1, '空白': 1, '日期': 1, '即便': 1, '暖': 1, '心': 1, '永遠都是': 1, '快樂': 1, '使': 1, '榮獲': 1, '好友': 1, '見證': 1, '一刻': 1, '背面': 1, '填寫': 1, '永遠': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#文本資料處理"
      ],
      "metadata": {
        "id": "vZ4-BU5SXhiZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "資料庫Python 提供了許多用於處理文本的庫和模組。以下是一些常用的操作與工具：\n",
        "\n",
        "\n",
        "* 正則表達式 re\n",
        "* Natural Language Toolkit(NLTK)\n",
        "* Jieba\n",
        "\n"
      ],
      "metadata": {
        "id": "W7KZ48YZXnbV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 正則表達式\n",
        "\n",
        "---\n",
        "\n",
        "正則表達式是一種強大的文本處理工具，可用於搜索、替換和提取文本。Python 內置了 re 函式庫，用於處理正則表達式"
      ],
      "metadata": {
        "id": "o1a1E2-cYMBS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "text = 'The quick brown fox jumps over the lazy dog.'\n",
        "result = re.search(r'fox', text)\n",
        "print(result.group(0)) # fox"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bv2M19VFYK_E",
        "outputId": "43f12f60-4681-499d-ccc7-619f71d3b857"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fox\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"John Doe, jane.doe@example.com\"\n",
        "pattern = r\"(\\w+) (\\w+), (\\w+.\\w+@\\w+\\.\\w+)\"\n",
        "\n",
        "match = re.search(pattern, text)\n",
        "\n",
        "if match:\n",
        "  print(match.group(1))   # Output: John\n",
        "  print(match.group(2))   # Output: Doe\n",
        "  print(match.group(3))   # Output: jane.doe@example.com"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CoDo5A0YZL-t",
        "outputId": "3190cb5f-67ab-4137-8f80-eba919b7bb79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "John\n",
            "Doe\n",
            "jane.doe@example.com\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NLTK\n",
        "\n",
        "---\n",
        "\n",
        "提供了許多自然語言處理的工具和資源。它可以用於分詞、標記、詞性標注和文本分析。"
      ],
      "metadata": {
        "id": "g5TYAK6jZVau"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "9_mg524hZcos",
        "outputId": "b2d209f1-63f4-4fac-e1b2-0cecd511af8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'The quick brown fox jumps over the lazy dog.'\n",
        "tokens = nltk.word_tokenize(text)\n",
        "print(tokens) # ['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', '.']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0t4fYGOanew",
        "outputId": "02203189-3738-41fb-9b7e-5f4895f07938"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[i for i in text.split(\" \")] #差在最後的那個句點"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDPekfqHarrf",
        "outputId": "4f3739f2-4187-4672-9590-c4d2b83402f3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog.']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Jieba\n",
        "\n",
        "---\n",
        "\n",
        "對於中文的自然語言處理，Jieba 是一個流行的 Python 函式庫。Jieba 提供了分詞、詞性標注、關鍵詞提取等功能，是進行中文文本處理的好幫手。"
      ],
      "metadata": {
        "id": "sJhCLMBXbLoH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (1)將中文文本分成詞語，可以使用 Jieba 的 cut 方法"
      ],
      "metadata": {
        "id": "4jsa1GEebWUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import jieba"
      ],
      "metadata": {
        "id": "Q5V-zKqAbSNp"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = '我喜歡用Python編程'\n",
        "words = jieba.cut(text) #返回的是一个 generator，即生成器\n",
        "print('/'.join(words)) # 我喜/歡用/Python/編程"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYkuEA7WbkFH",
        "outputId": "5da42a77-24ae-44b0-8984-b039d5ba3209"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "我喜/歡用/Python/編程\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###(2) 對中文文本進行詞性標注，可以使用 Jieba 的 posseg 方法。"
      ],
      "metadata": {
        "id": "ufsSGok3dYKA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import jieba.posseg as pseg\n",
        "\n",
        "text = '我喜歡用Python編程'\n",
        "words = pseg.cut(text)\n",
        "for word, pos in words:\n",
        "    print(word, pos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eBDX--odbQ3",
        "outputId": "fbf8b3be-b1c1-4af0-c79f-77fe4e7d01a0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'generator'>\n",
            "我 r\n",
            "喜歡 v\n",
            "用 p\n",
            "Python eng\n",
            "編程 n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###(3) 提取中文文本的關鍵詞，可以使用 Jieba 的 extract_tags 方法"
      ],
      "metadata": {
        "id": "aj_Uh3gcduRp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import jieba.analyse\n",
        "\n",
        "text = '我喜歡用Python編程'\n",
        "keywords = jieba.analyse.extract_tags(text, topK=3)\n",
        "print(keywords) # ['Python', '喜歡', '編程']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPPpKQkxdvOc",
        "outputId": "3eb5c6ac-53cc-4804-9343-634d8ac933b0"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['我喜', '歡用', 'Python']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 自然語言處理\n",
        "\n",
        "---\n",
        "在自然語言處理中，您可以使用 Python 來進行各種文本分析、語言模型、情感分析等工作。\n"
      ],
      "metadata": {
        "id": "Xkqt3g9tX-ff"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###TextBlob\n",
        "\n",
        "---\n",
        "TextBlob 是一個基於 NLTK 的 Python 库，提供了一個簡單的 API，用於文本分析、情感分析和主題分析。\n"
      ],
      "metadata": {
        "id": "j0bKdMS1d1dL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "text = 'I love Python!'\n",
        "blob = TextBlob(text)\n",
        "print(blob.sentiment.polarity) # 0.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtjCgNLyd8Xg",
        "outputId": "36b8ae3e-f835-4b41-a98a-f78a4a17fac2"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###gensim\n",
        "\n",
        "---\n",
        "\n",
        "gensim 是一個用於主題建模和相似度比較的 Python 函式庫。它可以用於建立文檔、詞彙和主題模型，以及進行文本\"相似度\"比較"
      ],
      "metadata": {
        "id": "zNGLV0u2eBtZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim import corpora, models, similarities\n",
        "\n",
        "documents = [\n",
        "    \"The quick brown fox jumps over the lazy dog\",\n",
        "    \"A king's breakfast has sausages, ham, bacon, eggs, toast and beans\", \n",
        "    \"I love Python and machine learning\"\n",
        "]\n",
        "texts = [[word for word in document.lower().split()] for document in documents]\n",
        "dictionary = corpora.Dictionary(texts)\n",
        "corpus = [dictionary.doc2bow(text) for text in texts]\n",
        "tfidf = models.TfidfModel(corpus)             #計算corpus中每個單詞的TF-IDF權重(tfidf)\n",
        "index = similarities.SparseMatrixSimilarity(tfidf[corpus], num_features=len(dictionary))\n",
        "query = \"Python and machine learning\"\n",
        "query_bow = dictionary.doc2bow(query.lower().split())\n",
        "sims = index[tfidf[query_bow]]\n",
        "print(list(enumerate(sims)))\n",
        "# [(0, 0.0), (1, 0.024158917), (2, 0.78141415)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rII0AZFeFaZ",
        "outputId": "7b772b45-f902-460e-d178-d4bb7fefb96d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, 0.0), (1, 0.024158917), (2, 0.78141415)]\n"
          ]
        }
      ]
    }
  ]
}
